# ğŸ“š Survey

| åç§° | é“¾æ¥ | å¹´ä»½ | æ¶‰åŠçš„<br>é¢†åŸŸ | ä»£ç  | åˆ›æ–°ç‚¹ | ä¸è¶³ç‚¹ |
|:----|:----|:----:|:--------------:|:----:|:------|:------|
| <small>FovEx: Human-Inspired Explanations for Vision Transformers and CNNs</small> | <small>[IJCV](https://arxiv.org/abs/2408.02123)</small> | <small>2025</small> | <small>è§†è§‰å¯è§£é‡Šæ€§</small> | <small>[GitHub](https://github.com/mahadev1995/FovEx)</small> | <small>[æ¦‚è¿°](#fovex-ijcv-2025)</small> | <small>[æ¦‚è¿°](#fovex-ijcv-2025)</small> |
| <small>MaIR: A Locality- and Continuity-Preserving Mamba for Image Restoration</small> | <small>[CVPR](https://arxiv.org/abs/2412.20066)</small> | <small>2025</small> | <small>é€šç”¨å›¾åƒæ¢å¤ </small> | <small>[GitHub](https://github.com/XLearning-SCU/2025-CVPR-MaIR)</small> | <small>[æ¦‚è¿°](#mair-cvpr-2025)</small> | <small>[æ¦‚è¿°](#mair-cvpr-2025)</small> |
| <small>Visual-Instructed Degradation Diffusion for All-in-One Image Restoration</small> | <small>[CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Luo_Visual-Instructed_Degradation_Diffusion_for_All-in-One_Image_Restoration_CVPR_2025_paper.pdf)</small> | <small>2025</small> | <small>ä¸€ä½“åŒ–å›¾åƒæ¢å¤</small> | <small>[GitHub](https://github.com/luowyang/Defusion)</small> | <small>[æ¦‚è¿°](#defusion-cvpr-2025)</small> | <small>[æ¦‚è¿°](#defusion-cvpr-2025)</small> |
| <small>DarkIR: Robust Low-Light Image Restoration</small> | <small>[arXiv](https://arxiv.org/abs/2412.13443)</small> | <small>2025</small> | <small>ä½ç…§åº¦å›¾åƒæ¢å¤</small> | <small>[GitHub](https://github.com/cidautai/DarkIR)</small> | <small>[æ¦‚è¿°](#darkir-cvpr-2025)</small> | <small>[æ¦‚è¿°](#darkir-cvpr-2025)</small> |
| <small>FaithDiff: Unleashing Diffusion Priors for Faithful Image Super-resolution</small> | <small>[CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_FaithDiff_Unleashing_Diffusion_Priors_for_Faithful_Image_Super-resolution_CVPR_2025_paper.pdf)</small> | <small>2025</small> | <small>å›¾åƒè¶…åˆ†è¾¨ç‡</small> | <small>[GitHub](https://github.com/JyChen9811/FaithDiff)</small> | <small>[æ¦‚è¿°](#faithdiff-cvpr-2025)</small> | <small>[æ¦‚è¿°](#faithdiff-cvpr-2025)</small> |
| <small>Multimodal Autoregressive Pre-training of Large Vision Encoders (AIMv2)</small> | <small>[CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Fini_Multimodal_Autoregressive_Pre-training_of_Large_Vision_Encoders_CVPR_2025_paper.pdf)</small> | <small>2025</small> | <small>å¤šæ¨¡æ€è§†è§‰é¢„è®­ç»ƒ</small> | <small>[GitHub](https://github.com/apple/ml-aim)</small> | <small>[æ¦‚è¿°](#aimv2-cvpr-2025)</small> | <small>[æ¦‚è¿°](#aimv2-cvpr-2025)</small> |
| <small>Task Preference Optimization: Improving Multimodal Large Language Models with Vision Task Alignment</small> | <small>[CVPR](https://openaccess.thecvf.com/content/CVPR2025/html/Yan_Task_Preference_Optimization_Improving_Multimodal_Large_Language_Models_with_Vision_CVPR_2025_paper.html)</small> | <small>2025</small> | <small>MLLM è§†è§‰ä»»åŠ¡å¯¹é½</small> | <small>[GitHub](https://github.com/OpenGVLab/TPO)</small> | <small>[æ¦‚è¿°](#tpo-cvpr-2025)</small> | <small>[æ¦‚è¿°](#tpo-cvpr-2025)</small> |
| <small>Multi-Layer Visual Feature Fusion in Multimodal LLMs: Methods, Analysis, and Best Practices</small> | <small>[è®ºæ–‡é¡µ](https://www.researchgate.net/publication/394621062_Multi-Layer_Visual_Feature_Fusion_in_Multimodal_LLMs_Methods_Analysis_and_Best_Practices)</small> | <small>2025</small> | <small>å¤šå±‚è§†è§‰ç‰¹å¾èåˆ</small> | <small>[GitHub](https://github.com/EIT-NLP/Layer_Select_Fuse_for_MLLM)</small> | <small>[æ¦‚è¿°](#multi-layer-fusion-cvpr-2025)</small> | <small>[æ¦‚è¿°](#multi-layer-fusion-cvpr-2025)</small> |
---

## ğŸ“– è®ºæ–‡è¯¦ç»†ç¬”è®°
<a id="fovex-ijcv-2025"></a>
### FovEx ï¼ˆIJCV 2025ï¼‰

**åˆ›æ–°ç‚¹ï¼š**
æœ¬æ–‡æå‡ºäº† FovExï¼Œè¿™ä¸€ç»“åˆç±»äººå‡¹è§†æœºåˆ¶ä¸æ¢¯åº¦é©±åŠ¨æ‰«è§†ã€å¯åŒæ—¶é€‚ç”¨äº CNN ä¸ ViT çš„ç»Ÿä¸€ XAI æ–¹æ³•ï¼Œåœ¨å¤šé¡¹ä¿¡èµ–åº¦æŒ‡æ ‡ä¸äººçœ¼å‡è§†ä¸€è‡´æ€§ä¸Šä¼˜äºç°æœ‰æ–¹æ³•

**ä¸è¶³ç‚¹ï¼š**
ä¼˜åŒ–ç›®æ ‡åå‘â€œä¿ç•™â€å…³é”®ä¿¡æ¯å¯¼è‡´åœ¨ DELETE æŒ‡æ ‡ä¸Šè¡¨ç°æ¬ ä½³ä¸”ä»…åœ¨æœ‰é™æ•°æ®é›†ä¸ä»»åŠ¡ä¸ŠéªŒè¯ï¼Œå­˜åœ¨æ³›åŒ–æ€§å’Œäººç¾¤åç½®æ–¹é¢çš„æ½œåœ¨å±€é™ã€‚
<a id="mair-cvpr-2025"></a>
### MaIR: A Locality- and Continuity-Preserving Mamba for Image Restorationï¼ˆCVPR 2025ï¼‰

**åˆ›æ–°ç‚¹ï¼š**
MaIR æå‡ºåœ¨ Mamba çŠ¶æ€ç©ºé—´æ¨¡å‹é‡ŒåŠ å…¥ Nested S-shaped Scanningï¼ˆNSSï¼‰+ Sequence Shuffle Attentionï¼ˆSSAï¼‰ï¼ŒåŒæ—¶ä¿æŒå›¾åƒçš„å±€éƒ¨æ€§å’Œç©ºé—´è¿ç»­æ€§ï¼Œç›¸æ¯”ä»¥å¾€ç®€å•æŒ‰è¡Œ/åˆ—å±•å¹³æˆ 1D åºåˆ—çš„ Mamba æ–¹æ¡ˆï¼Œåœ¨è¶…åˆ†ã€å»å™ªã€å»æ¨¡ç³Šã€å»é›¾ç­‰ 4 å¤§ä»»åŠ¡ã€14 ä¸ªæ•°æ®é›†ä¸Šå…¨é¢åˆ·äº† 40 ä¸ªåŸºçº¿ã€‚

**ä¸è¶³ç‚¹ï¼š**
ä¸»è¦è¿˜æ˜¯åœ¨é…å¯¹çš„æ ‡å‡†ä½å±‚è§†è§‰åŸºå‡†ä¸Šåšå®éªŒï¼Œå¯¹çœŸå®æœªçŸ¥é€€åŒ–ï¼ˆJPEG å‹ç¼©ã€ç›¸æœº ISPã€æ··åˆé€€åŒ–ç­‰ï¼‰çš„éªŒè¯æœ‰é™ï¼Œè€Œä¸” Mamba ç»“æ„æœ¬èº«æ¯”è¾ƒå¤æ‚ï¼Œè®­ç»ƒæˆæœ¬å’Œå·¥ç¨‹è½åœ°é—¨æ§›éƒ½ä¸ç®—ä½ã€‚
